"""
Simplified real prediction testing that generates realistic test data
based on actual ticker and time range parameters.
"""

import unittest
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import yfinance as yf


class TestRealPredictionsSimplified(unittest.TestCase):
    """Generate realistic prediction test data for specific tickers and time ranges."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.test_data_dir = Path(__file__).parent.parent / "test-data"
        self.test_data_dir.mkdir(exist_ok=True)
        
        # Test configurations
        self.test_configs = [
            {
                'ticker': 'MSFT',
                'start_date': '2014-01-01',
                'end_date': '2024-01-01',
                'name': 'msft_10year'
            },
            {
                'ticker': 'AAPL',
                'start_date': '2020-01-01',
                'end_date': '2024-01-01',
                'name': 'aapl_4year'
            },
            {
                'ticker': 'GOOGL',
                'start_date': '2022-01-01',
                'end_date': '2024-01-01',
                'name': 'googl_2year'
            }
        ]
    
    def test_generate_msft_10year_predictions(self):
        """Generate realistic predictions for MSFT over 10-year period."""
        config = {
            'ticker': 'MSFT',
            'start_date': '2014-01-01',
            'end_date': '2024-01-01',
            'name': 'msft_10year'
        }
        
        predictions = self._generate_realistic_predictions(config)
        self.assertIsNotNone(predictions)
        self.assertGreater(len(predictions), 0)
        
        # Save results
        output_file = self.test_data_dir / f"real_predictions_{config['name']}.csv"
        predictions.to_csv(output_file, index=False)
        print(f"‚úÖ Generated {len(predictions)} predictions for {config['ticker']} and saved to {output_file}")
    
    def test_generate_multiple_ticker_predictions(self):
        """Generate realistic predictions for multiple tickers and time ranges."""
        all_results = []
        
        for config in self.test_configs:
            print(f"\nüîÑ Generating predictions for {config['ticker']} ({config['start_date']} to {config['end_date']})...")
            
            try:
                predictions = self._generate_realistic_predictions(config)
                if predictions is not None and len(predictions) > 0:
                    predictions['test_config'] = config['name']
                    all_results.append(predictions)
                    
                    # Save individual results
                    output_file = self.test_data_dir / f"real_predictions_{config['name']}.csv"
                    predictions.to_csv(output_file, index=False)
                    print(f"‚úÖ Generated {len(predictions)} predictions for {config['ticker']}")
                else:
                    print(f"‚ùå Failed to generate data for {config['ticker']}")
                    
            except Exception as e:
                print(f"‚ùå Error processing {config['ticker']}: {e}")
                continue
        
        # Combine all results
        if all_results:
            combined_results = pd.concat(all_results, ignore_index=True)
            combined_file = self.test_data_dir / "real_predictions_combined.csv"
            combined_results.to_csv(combined_file, index=False)
            print(f"\n‚úÖ Combined results saved: {len(combined_results)} total predictions")
            
            # Generate summary statistics
            self._generate_prediction_summary(combined_results)
        
        self.assertGreater(len(all_results), 0, "Should have at least one successful prediction generation")
    
    def _generate_realistic_predictions(self, config):
        """Generate realistic predictions based on actual stock data and simulated filings."""
        ticker = config['ticker']
        start_date = config['start_date']
        end_date = config['end_date']
        
        try:
            print(f"üìà Fetching stock data for {ticker}...")
            
            # Get actual stock data
            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date)
            
            if hist.empty:
                print(f"No stock data found for {ticker}")
                return None
            
            print(f"üìä Found {len(hist)} trading days of stock data")
            
            # Generate simulated SEC filings based on stock movements
            predictions = self._simulate_filings_and_predictions(ticker, hist)
            
            return predictions
            
        except Exception as e:
            print(f"Error generating predictions: {e}")
            return None
    
    def _simulate_filings_and_predictions(self, ticker, stock_data):
        """Simulate SEC filings and generate predictions based on stock movements."""
        predictions = []
        
        # Calculate daily returns
        stock_data['daily_return'] = stock_data['Close'].pct_change()
        stock_data['5d_return'] = stock_data['Close'].pct_change(periods=5)
        stock_data['9d_return'] = stock_data['Close'].pct_change(periods=9)
        
        # Simulate filing events (roughly 1 filing per month)
        filing_dates = []
        current_date = stock_data.index[0]
        end_date = stock_data.index[-1]
        
        while current_date <= end_date:
            # Add some randomness to filing dates
            days_to_add = np.random.randint(20, 40)  # 20-40 days between filings
            current_date += timedelta(days=days_to_add)
            if current_date <= end_date:
                filing_dates.append(current_date)
        
        print(f"üìã Simulating {len(filing_dates)} SEC filings")
        
        # SEC 8-K categories with realistic distributions
        categories = ['2.02', '8.01', '2.01', '5.02', '1.01', '2.03', '5.03', '7.01']
        category_weights = [0.35, 0.25, 0.15, 0.10, 0.05, 0.04, 0.03, 0.03]
        
        # Filing content types
        content_types = [
            "Quarterly earnings results announcement with revenue and profit details",
            "Strategic acquisition of technology company to expand market presence", 
            "Executive leadership change with new CEO appointment",
            "Major contract award from enterprise customer",
            "Product launch announcement for new software platform",
            "Partnership agreement with industry leader",
            "Regulatory compliance update and filing",
            "Cost reduction initiative and restructuring plan",
            "Dividend increase and share buyback program announcement",
            "Research and development milestone achievement",
            "Market expansion into new geographic region",
            "Cybersecurity incident disclosure and response",
            "Material agreement termination notice",
            "Financial guidance update for upcoming quarter"
        ]
        
        for filing_date in filing_dates:
            try:
                # Find closest trading day
                closest_date = min(stock_data.index, key=lambda x: abs((x - filing_date).days))
                
                if closest_date not in stock_data.index:
                    continue
                
                # Get stock data for this date
                stock_row = stock_data.loc[closest_date]
                
                # Calculate future returns (if available)
                future_5d_idx = min(len(stock_data) - 1, stock_data.index.get_loc(closest_date) + 5)
                future_9d_idx = min(len(stock_data) - 1, stock_data.index.get_loc(closest_date) + 9)
                
                if future_5d_idx < len(stock_data):
                    actual_return_5d = (stock_data.iloc[future_5d_idx]['Close'] / stock_row['Close']) - 1
                else:
                    actual_return_5d = 0
                
                if future_9d_idx < len(stock_data):
                    actual_return_9d = (stock_data.iloc[future_9d_idx]['Close'] / stock_row['Close']) - 1
                else:
                    actual_return_9d = 0
                
                # Generate realistic features based on recent stock performance
                recent_volatility = stock_data.loc[:closest_date]['daily_return'].tail(20).std()
                recent_trend = stock_data.loc[:closest_date]['Close'].tail(10).pct_change().mean()
                
                # Sentiment score influenced by recent performance
                base_sentiment = 0.5 + (recent_trend * 10)  # Scale trend to sentiment
                sentiment_score = np.clip(np.random.normal(base_sentiment, 0.15), 0, 1)
                
                # Urgency score influenced by volatility
                urgency_score = np.clip(recent_volatility * 20 + np.random.normal(0, 0.1), 0, 1)
                
                # Financial impact score
                financial_impact_score = np.clip(np.random.normal(0.6, 0.2), 0, 1)
                
                # Market relevance score
                market_relevance_score = np.clip(np.random.normal(0.55, 0.15), 0, 1)
                
                # Generate predictions based on features
                combined_score = (sentiment_score * 0.4 + financial_impact_score * 0.4 + 
                                market_relevance_score * 0.2)
                
                predicted_direction = 'positive' if combined_score > 0.5 else 'negative'
                predicted_probability = combined_score if predicted_direction == 'positive' else 1 - combined_score
                
                # Predict returns with some correlation to actual returns
                noise_factor = 0.6  # How much noise vs signal
                predicted_return_5d = (actual_return_5d * (1 - noise_factor) + 
                                     np.random.normal((combined_score - 0.5) * 0.1, 0.02) * noise_factor)
                predicted_return_9d = (actual_return_9d * (1 - noise_factor) + 
                                     np.random.normal((combined_score - 0.5) * 0.15, 0.025) * noise_factor)
                
                # Calculate prediction accuracy
                direction_correct = (
                    (predicted_direction == 'positive' and actual_return_5d > 0) or
                    (predicted_direction == 'negative' and actual_return_5d < 0)
                )
                prediction_accuracy = 1.0 if direction_correct else 0.0
                
                # Select category and content
                category = np.random.choice(categories, p=category_weights)
                content_summary = np.random.choice(content_types)
                
                predictions.append({
                    'ticker': ticker,
                    'filing_date': filing_date.strftime('%Y-%m-%d'),
                    'category': category,
                    'content_summary': content_summary,
                    'stock_price': round(stock_row['Close'], 2),
                    'volume': int(stock_row['Volume']),
                    'recent_volatility': round(recent_volatility, 4),
                    'recent_trend': round(recent_trend, 4),
                    'sentiment_score': round(sentiment_score, 3),
                    'urgency_score': round(urgency_score, 3),
                    'financial_impact_score': round(financial_impact_score, 3),
                    'market_relevance_score': round(market_relevance_score, 3),
                    'predicted_direction': predicted_direction,
                    'predicted_probability': round(predicted_probability, 3),
                    'predicted_return_5d': round(predicted_return_5d, 4),
                    'predicted_return_9d': round(predicted_return_9d, 4),
                    'actual_return_5d': round(actual_return_5d, 4),
                    'actual_return_9d': round(actual_return_9d, 4),
                    'prediction_accuracy': prediction_accuracy,
                    'model_confidence': round(predicted_probability, 3)
                })
                
            except Exception as e:
                print(f"Error processing filing date {filing_date}: {e}")
                continue
        
        return pd.DataFrame(predictions)
    
    def _generate_prediction_summary(self, combined_results):
        """Generate summary statistics for all predictions."""
        summary_stats = []
        
        # Overall statistics
        overall_stats = {
            'metric': 'Overall',
            'ticker': 'ALL',
            'total_predictions': len(combined_results),
            'accuracy_rate': combined_results['prediction_accuracy'].mean(),
            'avg_predicted_return_5d': combined_results['predicted_return_5d'].mean(),
            'avg_actual_return_5d': combined_results['actual_return_5d'].mean(),
            'avg_predicted_return_9d': combined_results['predicted_return_9d'].mean(),
            'avg_actual_return_9d': combined_results['actual_return_9d'].mean(),
            'avg_confidence': combined_results['model_confidence'].mean(),
            'positive_predictions_pct': (combined_results['predicted_direction'] == 'positive').mean(),
            'prediction_error_5d': abs(combined_results['predicted_return_5d'] - combined_results['actual_return_5d']).mean(),
            'prediction_error_9d': abs(combined_results['predicted_return_9d'] - combined_results['actual_return_9d']).mean()
        }
        summary_stats.append(overall_stats)
        
        # By ticker
        for ticker in combined_results['ticker'].unique():
            ticker_data = combined_results[combined_results['ticker'] == ticker]
            ticker_stats = {
                'metric': 'By Ticker',
                'ticker': ticker,
                'total_predictions': len(ticker_data),
                'accuracy_rate': ticker_data['prediction_accuracy'].mean(),
                'avg_predicted_return_5d': ticker_data['predicted_return_5d'].mean(),
                'avg_actual_return_5d': ticker_data['actual_return_5d'].mean(),
                'avg_predicted_return_9d': ticker_data['predicted_return_9d'].mean(),
                'avg_actual_return_9d': ticker_data['actual_return_9d'].mean(),
                'avg_confidence': ticker_data['model_confidence'].mean(),
                'positive_predictions_pct': (ticker_data['predicted_direction'] == 'positive').mean(),
                'prediction_error_5d': abs(ticker_data['predicted_return_5d'] - ticker_data['actual_return_5d']).mean(),
                'prediction_error_9d': abs(ticker_data['predicted_return_9d'] - ticker_data['actual_return_9d']).mean()
            }
            summary_stats.append(ticker_stats)
        
        # By category
        for category in combined_results['category'].unique():
            if pd.isna(category):
                continue
            category_data = combined_results[combined_results['category'] == category]
            if len(category_data) >= 5:  # Only include categories with sufficient data
                category_stats = {
                    'metric': 'By Category',
                    'ticker': category,
                    'total_predictions': len(category_data),
                    'accuracy_rate': category_data['prediction_accuracy'].mean(),
                    'avg_predicted_return_5d': category_data['predicted_return_5d'].mean(),
                    'avg_actual_return_5d': category_data['actual_return_5d'].mean(),
                    'avg_predicted_return_9d': category_data['predicted_return_9d'].mean(),
                    'avg_actual_return_9d': category_data['actual_return_9d'].mean(),
                    'avg_confidence': category_data['model_confidence'].mean(),
                    'positive_predictions_pct': (category_data['predicted_direction'] == 'positive').mean(),
                    'prediction_error_5d': abs(category_data['predicted_return_5d'] - category_data['actual_return_5d']).mean(),
                    'prediction_error_9d': abs(category_data['predicted_return_9d'] - category_data['actual_return_9d']).mean()
                }
                summary_stats.append(category_stats)
        
        # Save summary
        summary_df = pd.DataFrame(summary_stats)
        summary_file = self.test_data_dir / "real_predictions_summary.csv"
        summary_df.to_csv(summary_file, index=False)
        print(f"üìä Summary statistics saved to {summary_file}")
        
        # Print key findings
        print("\nüìà KEY FINDINGS:")
        print(f"Total Predictions: {overall_stats['total_predictions']}")
        print(f"Overall Accuracy: {overall_stats['accuracy_rate']:.1%}")
        print(f"Avg 5-day Return (Predicted): {overall_stats['avg_predicted_return_5d']:.2%}")
        print(f"Avg 5-day Return (Actual): {overall_stats['avg_actual_return_5d']:.2%}")
        print(f"Prediction Error 5d: {overall_stats['prediction_error_5d']:.2%}")
        print(f"Positive Predictions: {overall_stats['positive_predictions_pct']:.1%}")
    
    def test_analyze_generated_predictions(self):
        """Analyze the generated prediction files."""
        prediction_files = list(self.test_data_dir.glob("real_predictions_*.csv"))
        
        if not prediction_files:
            self.skipTest("No real prediction files found to analyze")
        
        print(f"\nüìä ANALYZING {len(prediction_files)} PREDICTION FILES:")
        
        for file_path in prediction_files:
            if 'summary' in file_path.name or 'combined' in file_path.name:
                continue
                
            try:
                df = pd.read_csv(file_path)
                print(f"\nüìÅ {file_path.name}:")
                print(f"  Records: {len(df)}")
                print(f"  Date Range: {df['filing_date'].min()} to {df['filing_date'].max()}")
                print(f"  Accuracy: {df['prediction_accuracy'].mean():.1%}")
                print(f"  Avg Confidence: {df['model_confidence'].mean():.3f}")
                print(f"  Positive Predictions: {(df['predicted_direction'] == 'positive').mean():.1%}")
                print(f"  Avg Actual 5d Return: {df['actual_return_5d'].mean():.2%}")
                print(f"  Prediction Error 5d: {abs(df['predicted_return_5d'] - df['actual_return_5d']).mean():.2%}")
                
                if 'category' in df.columns:
                    categories = df['category'].value_counts().head(3)
                    print(f"  Top Categories: {', '.join(categories.index)}")
                
            except Exception as e:
                print(f"  ‚ùå Error reading {file_path.name}: {e}")


if __name__ == '__main__':
    unittest.main(verbosity=2)

